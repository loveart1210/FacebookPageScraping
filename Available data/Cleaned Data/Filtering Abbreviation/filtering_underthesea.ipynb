{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0496caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "from underthesea import word_tokenize\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "389d37f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình logging\n",
    "logging.basicConfig(\n",
    "    filename='processing.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filemode='w',  # Ghi đè file log mỗi lần chạy\n",
    "    encoding='utf-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bcb94eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danh sách từ viết tắt/lóng phổ biến trên mạng xã hội\n",
    "COMMON_ABBREVIATIONS = {\n",
    "    'ad', 'ib', 'tt', 'rep', 'dm', 'pm', 'acc', 'fb', 'zalo', 'ok', 'ko', 'dc',\n",
    "    'ns', 'vs', 'nt', 'cm', 'sp', 'pr', 'hot', 'top', 'vcl', 'wtf', 'lol', 'cfs'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7b3f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_abbreviations(post_text, index):\n",
    "    \"\"\"\n",
    "    Phát hiện các từ viết tắt hoặc thuật ngữ/ký hiệu không rõ ràng trong nội dung bài viết.\n",
    "    Xử lý Post Text là danh sách chuỗi.\n",
    "    Sử dụng underthesea để phân đoạn từ và danh sách từ viết tắt phổ biến.\n",
    "    Trả về danh sách các từ viết tắt duy nhất hoặc danh sách rỗng nếu không tìm thấy.\n",
    "    Ghi log lỗi nếu xảy ra.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Nếu post_text là danh sách, nối các chuỗi thành một chuỗi\n",
    "        if isinstance(post_text, list):\n",
    "            post_text = \" \".join(str(text) for text in post_text if pd.notnull(text))\n",
    "        else:\n",
    "            post_text = str(post_text) if pd.notnull(post_text) else \"\"\n",
    "\n",
    "        # Phân đoạn từ bằng underthesea\n",
    "        tokens = word_tokenize(post_text, format=\"text\").split()\n",
    "        # Lọc các từ ngắn (dưới 4 ký tự) hoặc trong danh sách từ viết tắt\n",
    "        abbreviations = set()\n",
    "        for token in tokens:\n",
    "            token = token.lower().strip()\n",
    "            # Kiểm tra từ ngắn hoặc trong danh sách từ viết tắt\n",
    "            if (len(token) <= 4 or token in COMMON_ABBREVIATIONS) and token.isalpha():\n",
    "                abbreviations.add(token)\n",
    "        return list(abbreviations)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Lỗi khi xử lý văn bản tại index {index}: {str(e)}\")\n",
    "        print(f\"Lỗi tại index {index}: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a5bf005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_file_encoding(file_path):\n",
    "    \"\"\"\n",
    "    Phát hiện mã hóa của file bằng charset-normalizer.\n",
    "    Trả về mã hóa được phát hiện hoặc None nếu thất bại.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            raw_data = f.read()\n",
    "        result = detect(raw_data)\n",
    "        encoding = result.get('encoding')\n",
    "        logging.info(f\"Phát hiện mã hóa của file {file_path}: {encoding}\")\n",
    "        return encoding\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Lỗi khi phát hiện mã hóa của file {file_path}: {str(e)}\")\n",
    "        print(f\"Lỗi khi phát hiện mã hóa của file {file_path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71638bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_file(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Xử lý file JSON để phát hiện các từ viết tắt và lưu kết quả vào file JSON.\n",
    "    Ghi log tiến độ, lỗi, thời gian thực hiện và ETA theo thời gian thực.\n",
    "    Hỗ trợ thử nhiều mã hóa khi đọc file JSON.\n",
    "    \"\"\"\n",
    "    # Đọc file JSON\n",
    "    encodings_to_try = ['utf-8', 'utf-16', 'latin1', 'cp1252']\n",
    "    data = None\n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            with open(input_file, 'r', encoding=encoding) as f:\n",
    "                data = json.load(f)\n",
    "            logging.info(f\"Đọc file JSON thành công với mã hóa {encoding}\")\n",
    "            break\n",
    "        except UnicodeDecodeError as e:\n",
    "            logging.warning(f\"Thất bại khi đọc file JSON với mã hóa {encoding}: {str(e)}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Lỗi khi đọc file JSON với mã hóa {encoding}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Nếu không đọc được với bất kỳ mã hóa nào\n",
    "    if data is None:\n",
    "        # Thử phát hiện mã hóa bằng charset-normalizer\n",
    "        detected_encoding = detect_file_encoding(input_file)\n",
    "        if detected_encoding:\n",
    "            try:\n",
    "                with open(input_file, 'r', encoding=detected_encoding) as f:\n",
    "                    data = json.load(f)\n",
    "                logging.info(f\"Đọc file JSON thành công với mã hóa được phát hiện: {detected_encoding}\")\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Lỗi khi đọc file JSON với mã hóa được phát hiện {detected_encoding}: {str(e)}\"\n",
    "                logging.error(error_msg)\n",
    "                print(error_msg)\n",
    "                return\n",
    "        else:\n",
    "            error_msg = f\"Không thể đọc file JSON {input_file} với bất kỳ mã hóa nào\"\n",
    "            logging.error(error_msg)\n",
    "            print(error_msg)\n",
    "            return\n",
    "\n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Lỗi khi chuyển JSON thành DataFrame: {str(e)}\")\n",
    "        print(f\"Lỗi khi chuyển JSON thành DataFrame: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Xác minh các cột bắt buộc\n",
    "    required_columns = ['index', 'Page URL', 'Page Name', 'Post URL', 'Post Text']\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        error_msg = f\"File JSON thiếu một hoặc nhiều cột bắt buộc: {required_columns}\"\n",
    "        logging.error(error_msg)\n",
    "        print(error_msg)\n",
    "        return\n",
    "\n",
    "    # Danh sách lưu kết quả\n",
    "    results = []\n",
    "    total_rows = len(df)  # Tổng số dòng trong file JSON\n",
    "    processed_rows = 0    # Số dòng đã xử lý\n",
    "    row_times = []        # Lưu thời gian xử lý mỗi dòng để tính ETA\n",
    "    start_time = time.time()\n",
    "\n",
    "    logging.info(f\"Bắt đầu xử lý {total_rows} dòng dữ liệu\")\n",
    "\n",
    "    # Xử lý từng dòng\n",
    "    for _, row in df.iterrows():\n",
    "        row_start_time = time.time()\n",
    "        index = int(row['index'])  # Chuyển index từ chuỗi sang số nguyên\n",
    "\n",
    "        # Lấy nội dung Post Text\n",
    "        post_text = row['Post Text']\n",
    "        abbreviations = detect_abbreviations(post_text, index) if post_text else []\n",
    "\n",
    "        # Tạo bản ghi kết quả\n",
    "        result = {\n",
    "            \"index\": index,\n",
    "            \"Page URL\": str(row['Page URL']),\n",
    "            \"Page Name\": str(row['Page Name']),\n",
    "            \"Post URL\": str(row['Post URL']),\n",
    "            \"Post Text\": post_text,  # Giữ nguyên dạng danh sách trong đầu ra\n",
    "            \"Abbreviation\": abbreviations\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "        # Tăng số dòng đã xử lý\n",
    "        processed_rows += 1\n",
    "        # Tính thời gian xử lý dòng hiện tại và cập nhật danh sách\n",
    "        row_time = time.time() - row_start_time\n",
    "        row_times.append(row_time)\n",
    "        # Lấy trung bình động (moving average) của 10 dòng gần nhất để tính ETA\n",
    "        avg_time_per_row = sum(row_times[-10:]) / min(len(row_times), 10)\n",
    "        eta = avg_time_per_row * (total_rows - processed_rows)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        # Ghi log và in tiến độ\n",
    "        progress_msg = (f\"Đã xử lý {processed_rows}/{total_rows} dòng (Index: {index}) \"\n",
    "                       f\"| Thời gian đã trôi qua: {elapsed_time:.2f}s | ETA: {eta:.2f}s\")\n",
    "        logging.info(progress_msg)\n",
    "        print(progress_msg)\n",
    "\n",
    "    # Ghi kết quả ra file JSON\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)  # Tạo thư mục nếu chưa tồn tại\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "        logging.info(f\"Kết quả đã được lưu vào {output_file}\")\n",
    "        print(f\"Kết quả đã được lưu vào {output_file}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Lỗi khi ghi file JSON: {str(e)}\")\n",
    "        print(f\"Lỗi khi ghi file JSON: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59f741b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lỗi khi phát hiện mã hóa của file ../../Facebook Page Posts Scraping/Clean Data/output/Confessions of HNMU.xlsx: name 'detect' is not defined\n",
      "Không thể đọc file JSON ../../Facebook Page Posts Scraping/Clean Data/output/Confessions of HNMU.xlsx với bất kỳ mã hóa nào\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_file = \"../../Facebook Page Posts Scraping/Clean Data/output/Confessions of HNMU.xlsx\"\n",
    "    output_file = \"output/Confessions of HNMU.json\"\n",
    "    process_json_file(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
