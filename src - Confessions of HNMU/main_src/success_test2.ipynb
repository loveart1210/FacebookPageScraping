{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece30fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.remote.client_config import ClientConfig\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import re, os\n",
    "\n",
    "from urllib.parse import urlparse, parse_qs, urlencode\n",
    "\n",
    "import random\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4b85914",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAGE_URL = \"https://www.facebook.com/profile.php?id=61555234277669\"\n",
    "OUTPUT_JSONL_FILE = \"output/3_confessions_of_hnmu.jsonl\"   # output ch√≠nh (JSONL)\n",
    "OUTPUT_JSON_FILE  = \"output/3_confessions_of_hnmu.json\"    # file JSON array sau khi convert\n",
    "CHECKPOINT_FILE   = \"output/3_checkpoint_hnmu.json\"\n",
    "COOKIES_FILE = \"cookies.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ec7509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S·ªë b√†i mu·ªën crawl\n",
    "crawl_post = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d3049b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cookies(driver, cookies_file):\n",
    "    with open(cookies_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        cookies = json.load(f)\n",
    "        for cookie in cookies:\n",
    "            c = {\n",
    "                \"name\": cookie[\"name\"],\n",
    "                \"value\": cookie[\"value\"],\n",
    "                \"domain\": cookie.get(\"domain\", \".facebook.com\"),\n",
    "                \"path\": cookie.get(\"path\", \"/\"),\n",
    "                \"secure\": cookie.get(\"secure\", True),\n",
    "                \"httpOnly\": cookie.get(\"httpOnly\", False),\n",
    "            }\n",
    "            # EditThisCookie d√πng 'expirationDate' (float gi√¢y). Selenium ch·∫•p nh·∫≠n 'expiry' (int).\n",
    "            if \"expirationDate\" in cookie:\n",
    "                try:\n",
    "                    c[\"expiry\"] = int(float(cookie[\"expirationDate\"]))\n",
    "                except Exception:\n",
    "                    pass\n",
    "            try:\n",
    "                driver.add_cookie(c)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Kh√¥ng th√™m ƒë∆∞·ª£c cookie {cookie.get('name')}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a382897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_all_see_more(driver, post):\n",
    "    try:\n",
    "        # M·ªü r·ªông caption\n",
    "        see_more_btns = post.find_elements(\n",
    "            By.XPATH,\n",
    "            \".//div[@role='button' and (contains(.,'See more') or contains(.,'Xem th√™m'))]\"\n",
    "        )\n",
    "        for btn in see_more_btns:\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", btn)\n",
    "                time.sleep(0.2)\n",
    "                try:\n",
    "                    btn.click()\n",
    "                except Exception:\n",
    "                    driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                time.sleep(0.6)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        # M·ªü r·ªông b·∫£n d·ªãch / nguy√™n b·∫£n (nhi·ªÅu b√†i n·∫±m sau thao t√°c n√†y)\n",
    "        translate_btns = post.find_elements(\n",
    "            By.XPATH,\n",
    "            \".//div[@role='button' and (contains(.,'Xem b·∫£n d·ªãch') or contains(.,'See translation') or contains(.,'Xem nguy√™n b·∫£n') or contains(.,'See original'))]\"\n",
    "        )\n",
    "        for btn in translate_btns:\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", btn)\n",
    "                time.sleep(0.2)\n",
    "                try:\n",
    "                    btn.click()\n",
    "                except Exception:\n",
    "                    driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                time.sleep(0.6)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f76d5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_post_link(post):\n",
    "    # 1. ∆Øu ti√™n: link ch·ª©a timestamp (th∆∞·ªùng l√† permalink g·ªëc)\n",
    "    try:\n",
    "        ts_links = post.find_elements(\n",
    "            By.XPATH,\n",
    "            './/a[contains(@href,\"permalink\") or contains(@href,\"story.php\")]/span/time/..'\n",
    "        )\n",
    "        if ts_links:\n",
    "            link = ts_links[0].get_attribute(\"href\")\n",
    "            print(\">>> Picked link:\", link)   # üëà in ra ƒë·ªÉ debug\n",
    "            return link\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2. N·∫øu kh√¥ng c√≥ timestamp th√¨ fallback theo pattern c≈©\n",
    "    patterns = [\n",
    "        'contains(@href,\"/posts/\")',\n",
    "        'contains(@href,\"story.php\")',\n",
    "        'contains(@href,\"permalink\")',\n",
    "        'contains(@href,\"photo.php\")',\n",
    "        'contains(@href,\"/video\")'\n",
    "    ]\n",
    "    for p in patterns:\n",
    "        els = post.find_elements(By.XPATH, f'.//a[{p}]')\n",
    "        if els:\n",
    "            link = els[0].get_attribute(\"href\")\n",
    "            print(f\">>> Picked link by pattern {p}:\", link)\n",
    "            return link\n",
    "\n",
    "    # 3. Cu·ªëi c√πng, fallback l·∫•y b·∫•t k·ª≥ link n√†o (√≠t d√πng)\n",
    "    any_a = post.find_elements(By.XPATH, './/a[@href]')\n",
    "    return any_a[0].get_attribute('href') if any_a else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "668055a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_post_url(url):\n",
    "    if not url:\n",
    "        return url\n",
    "    p = urlparse(url)\n",
    "    qs = parse_qs(p.query)\n",
    "    for k in list(qs.keys()):\n",
    "        if k.startswith(\"__cft__\") or k in {\"__tn__\", \"comment_id\", \"mibextid\", \"refid\"}:\n",
    "            qs.pop(k, None)\n",
    "    q = urlencode(qs, doseq=True)\n",
    "    return f\"{p.scheme}://{p.netloc}{p.path}\" + (f\"?{q}\" if q else \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1095a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(processed, seen_urls):\n",
    "    os.makedirs(os.path.dirname(CHECKPOINT_FILE), exist_ok=True)\n",
    "    with open(CHECKPOINT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"processed\": int(processed), \"seen_urls\": list(seen_urls)}, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d91d958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint():\n",
    "    try:\n",
    "        with open(CHECKPOINT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            d = json.load(f)\n",
    "            return int(d.get(\"processed\", 0)), set(d.get(\"seen_urls\", []))\n",
    "    except Exception:\n",
    "        return 0, set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae0b4047",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_WORDS = {\n",
    "    \"like\", \"reply\", \"share\", \"comment\", \"send\", \"follow\",\n",
    "    \"th√≠ch\", \"tr·∫£ l·ªùi\", \"chia s·∫ª\", \"b√¨nh lu·∫≠n\", \"g·ª≠i\", \"theo d√µi\", \"ph·∫£n h·ªìi\"\n",
    "}\n",
    "TIME_RE = re.compile(r\"^\\d+\\s*(s|m|h|d|w|y)$\", re.I)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a128554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_noise(t: str) -> bool:\n",
    "    s = t.strip()\n",
    "    if not s:\n",
    "        return True\n",
    "    if TIME_RE.match(s):\n",
    "        return True          # 1d, 3h, 15m...\n",
    "    if s.isdigit():\n",
    "        return True               # ‚Äú45‚Äù, ‚Äú2‚Äù (ƒë·∫øm)\n",
    "    low = s.lower()\n",
    "    if low in NOISE_WORDS:\n",
    "        return True        # Like/Reply/Share...\n",
    "    # d√≤ng r·∫•t ng·∫Øn v√† tr√πng t·ª´ h√†nh ƒë·ªông ‚Üí coi nh∆∞ r√°c\n",
    "    if len(s) <= 2:\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6de3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_message_container_text(post):\n",
    "    msg_nodes = post.find_elements(By.CSS_SELECTOR, 'div[data-ad-preview=\"message\"], div[data-ad-comet-preview=\"message\"]')\n",
    "    if msg_nodes:\n",
    "        t = (msg_nodes[0].get_attribute(\"textContent\") or \"\").strip()\n",
    "        return t\n",
    "\n",
    "    msg_nodes2 = post.find_elements(By.CSS_SELECTOR, 'div[data-ad-rendering-role=\"story_message\"]')\n",
    "    if msg_nodes2:\n",
    "        t = (msg_nodes2[0].get_attribute(\"textContent\") or \"\").strip()\n",
    "        return t\n",
    "\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e52f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_post_text_segments(driver, post):\n",
    "    expand_all_see_more(driver, post)\n",
    "\n",
    "    segs = []\n",
    "    selectors = [\n",
    "        \"div.xdj266r.x14z9mp.xat24cr.x1lziwak.x1vvkbs.x126k92a\",    # d√≤ng ƒë·∫ßu\n",
    "        \"div.x14z9mp.xat24cr.x1lziwak.x1vvkbs.xtlvy1s.x126k92a\"     # c√°c d√≤ng sau\n",
    "    ]\n",
    "\n",
    "    print(\">>> ƒêang l·∫•y text cho post...\")\n",
    "    for sel in selectors:\n",
    "        els = post.find_elements(By.CSS_SELECTOR, sel)\n",
    "        print(f\"Selector {sel} t√¨m th·∫•y {len(els)} elements\")\n",
    "        for el in els:\n",
    "            print(\"----\", (el.text or '').strip()[:80])\n",
    "\n",
    "    # ====== Logic c≈© gi·ªØ nguy√™n ======\n",
    "    for sel in selectors:\n",
    "        for el in post.find_elements(By.CSS_SELECTOR, sel):\n",
    "            try:\n",
    "                t = (el.get_attribute(\"textContent\") or \"\").strip()\n",
    "                if t and not _is_noise(t):\n",
    "                    segs.append(t)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    # =========================\n",
    "    # ADDED: fallback b·ªÅn v·ªØng h∆°n (container message)\n",
    "    # N·∫øu selector class kh√¥ng b·∫Øt ƒë∆∞·ª£c, v·∫´n l·∫•y ƒë∆∞·ª£c caption\n",
    "    # =========================\n",
    "    if not segs:\n",
    "        t = _extract_message_container_text(post)\n",
    "        if t:\n",
    "            # T√°ch theo d√≤ng ƒë·ªÉ t∆∞∆°ng th√≠ch output segments\n",
    "            lines = [x.strip() for x in t.split(\"\\n\") if x.strip()]\n",
    "            for ln in lines:\n",
    "                if ln and not _is_noise(ln):\n",
    "                    segs.append(ln)\n",
    "\n",
    "    # =========================\n",
    "    # ADDED: fallback cu·ªëi (dir=\"auto\" trong message container) ƒë·ªÉ h·∫°n ch·∫ø miss do split node\n",
    "    # =========================\n",
    "    if not segs:\n",
    "        msg_nodes = post.find_elements(By.CSS_SELECTOR, 'div[data-ad-preview=\"message\"], div[data-ad-comet-preview=\"message\"], div[data-ad-rendering-role=\"story_message\"]')\n",
    "        if msg_nodes:\n",
    "            container = msg_nodes[0]\n",
    "            for el in container.find_elements(By.CSS_SELECTOR, 'div[dir=\"auto\"]'):\n",
    "                try:\n",
    "                    t = (el.get_attribute(\"textContent\") or \"\").strip()\n",
    "                    if t and not _is_noise(t):\n",
    "                        segs.append(t)\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "    # Kh·ª≠ tr√πng l·∫∑p\n",
    "    seen, uniq = set(), []\n",
    "    for s in segs:\n",
    "        s = \" \".join(s.split())  # ADDED: normalize whitespace ƒë·ªÉ gi·∫£m duplicate do kho·∫£ng tr·∫Øng\n",
    "        if s and s not in seen:\n",
    "            seen.add(s)\n",
    "            uniq.append(s)\n",
    "    return uniq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed6b0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "    # Gi·∫£m t·∫£i: t·∫Øt ·∫£nh, h·∫°n ch·∫ø autoplay\n",
    "    prefs = {\n",
    "        \"profile.managed_default_content_settings.images\": 2,\n",
    "        \"profile.default_content_setting_values.notifications\": 2,\n",
    "        \"autoplay-policy\": \"document-user-activation-required\",\n",
    "    }\n",
    "    options.add_experimental_option(\"prefs\", prefs)\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(\"../../chromedriver-win64/chromedriver.exe\"),\n",
    "        options=options\n",
    "    )\n",
    "\n",
    "    # TƒÉng timeout cho c√°c l·ªánh script/page-load (·ªïn ƒë·ªãnh cho FB)\n",
    "    driver.set_page_load_timeout(300)\n",
    "    driver.set_script_timeout(300)\n",
    "\n",
    "    # TƒÉng timeout cho HTTP command Selenium ‚Üî ChromeDriver\n",
    "    try:\n",
    "        driver.command_executor.set_timeout(300)\n",
    "    except Exception:\n",
    "        # fallback cho m·ªôt s·ªë build\n",
    "        try:\n",
    "            driver.command_executor._conn.timeout = 300\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    driver.get(\"https://www.facebook.com\")\n",
    "    WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "    load_cookies(driver, COOKIES_FILE)\n",
    "    driver.refresh()\n",
    "    WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "\n",
    "    driver.get(PAGE_URL)\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='feed'], div[role='main']\"))\n",
    "    )\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d847c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_fanpage():\n",
    "    processed, seen_urls = load_checkpoint()\n",
    "    driver = build_driver()\n",
    "\n",
    "    # Cu·ªôn ƒë·ªÉ t·∫£i b√†i v√† ch·ªù ‚Äú·ªïn ƒë·ªãnh‚Äù\n",
    "    max_wait = 5\n",
    "    stagnant = 0\n",
    "\n",
    "    os.makedirs(os.path.dirname(OUTPUT_JSONL_FILE), exist_ok=True)\n",
    "\n",
    "    mode = \"a\" if (processed > 0 and os.path.exists(OUTPUT_JSONL_FILE)) else \"w\"\n",
    "    with open(OUTPUT_JSONL_FILE, mode, encoding=\"utf-8\") as f:\n",
    "        print(f\"üìú B·∫Øt ƒë·∫ßu cu·ªôn v√† x·ª≠ l√Ω ƒë·∫øn khi ƒë·ªß {crawl_post} b√†i... (resume={processed})\")\n",
    "\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while processed < crawl_post:\n",
    "            # --- TIMEOUT SELF-HEAL: n·∫øu find_elements b·ªã Read timed out th√¨ restart ---\n",
    "            try:\n",
    "                posts = driver.find_elements(By.CSS_SELECTOR, \"div.x1yztbdb.x1n2onr6.xh8yej3.x1ja2u2z\")\n",
    "            except Exception as e:\n",
    "                msg = str(e).lower()\n",
    "                if \"read timed out\" in msg or \"httppool\" in msg:\n",
    "                    print(\"‚ö†Ô∏è ChromeDriver timeout. Restart v√† resume...\")\n",
    "                    save_checkpoint(processed, seen_urls)\n",
    "                    try:\n",
    "                        driver.quit()\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    driver = None\n",
    "                    driver = build_driver()\n",
    "                    continue\n",
    "                raise\n",
    "\n",
    "            cur = len(posts)\n",
    "            print(f\"üîΩ ƒêang th·∫•y {cur} post tr√™n DOM | ƒë√£ l∆∞u {processed}\")\n",
    "\n",
    "            if cur <= processed:\n",
    "                for _ in range(8):\n",
    "                    ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "                    time.sleep(0.2)\n",
    "\n",
    "                time.sleep(2 + random.random())\n",
    "\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height <= last_height:\n",
    "                    stagnant += 1\n",
    "                    if stagnant >= max_wait:\n",
    "                        print(\"‚ö†Ô∏è Kh√¥ng th·∫•y n·ªôi dung m·ªõi (scrollHeight kh√¥ng tƒÉng), d·ª´ng.\")\n",
    "                        break\n",
    "                else:\n",
    "                    stagnant = 0\n",
    "                    last_height = new_height\n",
    "                continue\n",
    "\n",
    "            for i in range(processed, min(cur, crawl_post)):\n",
    "                try:\n",
    "                    # refetch theo index ƒë·ªÉ gi·∫£m stale\n",
    "                    posts = driver.find_elements(By.CSS_SELECTOR, \"div.x1yztbdb.x1n2onr6.xh8yej3.x1ja2u2z\")\n",
    "                    if i >= len(posts):\n",
    "                        break\n",
    "                    post = posts[i]\n",
    "\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", post)\n",
    "                    time.sleep(0.7)\n",
    "\n",
    "                    permalink = clean_post_url(pick_post_link(post)) or \"N/A\"\n",
    "\n",
    "                    # ch·ªëng tr√πng do FB re-render\n",
    "                    if permalink != \"N/A\" and permalink in seen_urls:\n",
    "                        processed += 1\n",
    "                        continue\n",
    "                    if permalink != \"N/A\":\n",
    "                        seen_urls.add(permalink)\n",
    "\n",
    "                    segs = extract_post_text_segments(driver, post)\n",
    "                    if not segs:\n",
    "                        print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y text... v·∫´n l∆∞u post_text=''\")\n",
    "\n",
    "                    data = {\n",
    "                        \"index\": processed + 1,\n",
    "                        \"page_url\": PAGE_URL,\n",
    "                        \"post_url\": permalink,\n",
    "                        \"segments\": segs,\n",
    "                        \"post_text\": \"\\n\".join(segs) if segs else \"\"\n",
    "                    }\n",
    "\n",
    "                    # --- JSONL: m·ªói d√≤ng 1 JSON object ---\n",
    "                    f.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "                    f.flush()\n",
    "\n",
    "                    # # --- d·ªçn DOM ƒë·ªÉ gi·∫£m RAM/ƒë∆° --- (t·∫°m t·∫Øt remove ƒë·ªÉ ki·ªÉm ch·ª©ng xem c√≤n d·ª´ng scraping s·ªõm hay kh√¥ng)\n",
    "                    # try:\n",
    "                    #     driver.execute_script(\"arguments[0].remove();\", post)\n",
    "                    # except Exception:\n",
    "                    #     pass\n",
    "\n",
    "                    processed += 1\n",
    "\n",
    "                    # checkpoint m·ªói 10 b√†i\n",
    "                    if processed % 10 == 0:\n",
    "                        save_checkpoint(processed, seen_urls)\n",
    "                        try:\n",
    "                            f.flush()\n",
    "                            os.fsync(f.fileno())\n",
    "                        except Exception:\n",
    "                            pass\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"‚ö†Ô∏è L·ªói x·ª≠ l√Ω m·ªôt b√†i:\", e)\n",
    "                    data = {\n",
    "                        \"index\": processed + 1,\n",
    "                        \"page_url\": PAGE_URL,\n",
    "                        \"post_url\": \"N/A\",\n",
    "                        \"segments\": [],\n",
    "                        \"post_text\": \"\"\n",
    "                    }\n",
    "                    f.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "                    f.flush()\n",
    "\n",
    "                    processed += 1\n",
    "                    if processed % 10 == 0:\n",
    "                        save_checkpoint(processed, seen_urls)\n",
    "                        try:\n",
    "                            f.flush()\n",
    "                            os.fsync(f.fileno())\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    continue\n",
    "\n",
    "        save_checkpoint(processed, seen_urls)\n",
    "        print(f\"‚úÖ ƒê√£ l∆∞u {processed} b√†i vi·∫øt v√†o {OUTPUT_JSONL_FILE}\")\n",
    "\n",
    "\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb357a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_to_json(jsonl_path=OUTPUT_JSONL_FILE, json_path=OUTPUT_JSON_FILE):\n",
    "    items = []\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            items.append(json.loads(line))\n",
    "\n",
    "    os.makedirs(os.path.dirname(json_path), exist_ok=True)\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(items, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"‚úÖ Convert xong: {len(items)} records -> {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b52687b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_15656\\1818628566.py:28: DeprecationWarning: set_timeout() in RemoteConnection is deprecated, set timeout in client_config instead\n",
      "  driver.command_executor.set_timeout(300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìú B·∫Øt ƒë·∫ßu cu·ªôn v√† x·ª≠ l√Ω ƒë·∫øn khi ƒë·ªß 3000 b√†i... (resume=0)\n",
      "üîΩ ƒêang th·∫•y 1 post tr√™n DOM | ƒë√£ l∆∞u 0\n",
      ">>> Picked link by pattern contains(@href,\"permalink\"): https://www.facebook.com/permalink.php?story_fbid=pfbid02G1DMb4ZvcV1RL2uMPVC3Z3G2RXFv6uQguCYzu14jjWjyHUufL6kAgzMLj9WgSp6Wl&id=61555234277669&__cft__[0]=AZZnxogbSr2qiLbExADWh-rB9femPnbjrCgEFfMi4UGuZ96HLVYNArM4Nk0R3L8leeAQkAl9D-XXaOsiyKwWYlB1MO60_bwwynvEGc4otUR586raoBrInv8r4uyDZeAdUBGe1EHwKbI-sT8NL4JRGhx49npV-SdViQpwVDZsieo6M1d_DduaVzI-K-KnyA-RiKMHP8N_50B8jA0UEasu28wp&__tn__=%2CO%2CP-R\n",
      ">>> ƒêang l·∫•y text cho post...\n",
      "Selector div.xdj266r.x14z9mp.xat24cr.x1lziwak.x1vvkbs.x126k92a t√¨m th·∫•y 1 elements\n",
      "---- H√¥m nay e c√≥ nh·∫∑t ƒëc th·∫ª sinh vi√™n n√†y b√™n gh·∫ø ƒë√° s√¢n k√Ω t√∫c x√° kh√¥ng bi·∫øt b·∫°n n\n",
      "Selector div.x14z9mp.xat24cr.x1lziwak.x1vvkbs.xtlvy1s.x126k92a t√¨m th·∫•y 0 elements\n",
      "üîΩ ƒêang th·∫•y 1 post tr√™n DOM | ƒë√£ l∆∞u 1\n",
      "üîΩ ƒêang th·∫•y 1 post tr√™n DOM | ƒë√£ l∆∞u 1\n",
      "üîΩ ƒêang th·∫•y 1 post tr√™n DOM | ƒë√£ l∆∞u 1\n",
      "üîΩ ƒêang th·∫•y 1 post tr√™n DOM | ƒë√£ l∆∞u 1\n",
      "üîΩ ƒêang th·∫•y 1 post tr√™n DOM | ƒë√£ l∆∞u 1\n",
      "‚ö†Ô∏è Kh√¥ng th·∫•y post m·ªõi, d·ª´ng.\n",
      "‚úÖ ƒê√£ l∆∞u 1 b√†i vi·∫øt v√†o output/3_confessions_of_hnmu.jsonl\n",
      "‚úÖ Convert xong: 1 records -> output/3_confessions_of_hnmu.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    crawl_fanpage()\n",
    "    jsonl_to_json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
